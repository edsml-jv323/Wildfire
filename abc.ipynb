{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VectorQuantizer(nn.Module):\n",
    "    \"\"\"\n",
    "    Discretization bottleneck part of the VQ-VAE.\n",
    "\n",
    "    Inputs:\n",
    "    - n_e : number of embeddings\n",
    "    - e_dim : dimension of embedding\n",
    "    - beta : commitment cost used in loss term, beta * ||z_e(x)-sg[e]||^2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_embeddings, embeddings_dim, beta=0.25):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        self.n_embeddings = n_embeddings\n",
    "        self.embeddings_dim = embeddings_dim\n",
    "        self.beta = beta\n",
    "\n",
    "        self.embedding = nn.Embedding(self.n_embeddings, self.embeddings_dim)\n",
    "        self.embedding.weight.data.uniform_(-1.0 / self.n_embeddings, 1.0 / self.n_embeddings)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Inputs the output of the encoder network z and maps it to a discrete \n",
    "        one-hot vector that is the index of the closest embedding vector e_j\n",
    "\n",
    "        z (continuous) -> z_q (discrete)\n",
    "\n",
    "        z.shape = (batch, channel, height, width)\n",
    "\n",
    "        quantization pipeline:\n",
    "\n",
    "            1. get encoder input (B,C,H,W)\n",
    "            2. flatten input to (B*H*W,C)\n",
    "\n",
    "        \"\"\"\n",
    "        # reshape z -> (batch, height, width, depth, channel) and flatten\n",
    "        z = z = z.permute(0, 2, 3, 4, 1).contiguous()\n",
    "        z_flattened = z.view(-1, self.embeddings_dim)\n",
    "        \n",
    "        # distances from z to embeddings e_j (z - e)^2 = z^2 + e^2 - 2 e * z\n",
    "        d = torch.sum(z_flattened ** 2, dim=1, keepdim=True) + \\\n",
    "            torch.sum(self.embedding.weight**2, dim=1) - 2 * \\\n",
    "            torch.matmul(z_flattened, self.embedding.weight.t())\n",
    "\n",
    "        # find closest encodings\n",
    "        min_encoding_indices = torch.argmin(d, dim=1).unsqueeze(1)\n",
    "        min_encodings = torch.zeros(\n",
    "            min_encoding_indices.shape[0], self.n_embeddings).to(device)\n",
    "        min_encodings.scatter_(1, min_encoding_indices, 1)\n",
    "\n",
    "        # get quantized latent vectors\n",
    "        z_q = torch.matmul(min_encodings, self.embedding.weight).view(z.shape)\n",
    "\n",
    "        # compute loss for embedding\n",
    "        loss = torch.mean((z_q.detach()-z)**2) + self.beta * \\\n",
    "            torch.mean((z_q - z.detach()) ** 2)\n",
    "\n",
    "        # preserve gradients\n",
    "        z_q = z + (z_q - z).detach()\n",
    "\n",
    "        # perplexity\n",
    "        e_mean = torch.mean(min_encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(e_mean * torch.log(e_mean + 1e-10)))\n",
    "        print(z_q.shape)\n",
    "        # reshape back to match original input shape\n",
    "        z_q = z_q.permute(0, 4,1,2,3).contiguous()\n",
    "\n",
    "        return loss, z_q, perplexity, min_encodings, min_encoding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VQVAE(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super(VQVAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=(3,4,4), stride=(1,2,2), padding=1),  # Example for 3D conv layer\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(16, 1, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pre_quantization_conv = nn.Conv3d(\n",
    "            1, embedding_dim, kernel_size=(3,4,4), stride=(1,2,2), padding = 1)\n",
    "        \n",
    "        self.VQ = VectorQuantizer(num_embeddings, embedding_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(embedding_dim, 1, kernel_size=(3,4,4), stride=(1,2,2), padding = 1\n",
    "                              ),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(1, 16, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose3d(16, 1, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.encode(x)\n",
    "        x = self.pre_quantization_conv(x)\n",
    "        print(x.shape, \"after prequant\")\n",
    "        embedding_loss, x, perplexity, _, _ = self.VQ(x)\n",
    "        print(x.shape, \"after quant\")\n",
    "        x_recon = self.decode(x)\n",
    "        print(x_recon.shape)\n",
    "        return embedding_loss, x, perplexity \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim = 8, channel_size = 9):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=(3,4,4), stride=(1,2,2), padding=1),  # Example for 3D conv layer\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv3d(16, 1, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*64*channel_size,64*channel_size),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "        )\n",
    "        ### Latent space transformations\n",
    "\n",
    "        self.mu = nn.Linear(64*channel_size,latent_dim)\n",
    "        self.logvar = nn.Linear(64*channel_size,latent_dim)\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(latent_dim, 64*channel_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64*channel_size,64*64*channel_size),\n",
    "            nn.Unflatten(1,(1,channel_size,64,64)),\n",
    "\n",
    "            nn.ConvTranspose3d(1, 16, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose3d(16, 1, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        \n",
    "        return mu, logvar\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)  # Calculate standard deviation from log variance\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "        \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim = 64, channel_size = 9,latent_pixel_size = 16):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            \n",
    "            nn.Conv3d(1, 8, kernel_size=(5,6,6), stride=(1,2,2), padding=(2,2,2)),  # Example for 3D conv layer\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            \n",
    "            nn.Conv3d(8, 16, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv3d(16,16, kernel_size = (3,3,3), stride= (1,1,1), padding = (1,1,1)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv3d(16,32, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv3d(32,32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "      \n",
    "    \n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*latent_pixel_size*latent_pixel_size*channel_size,256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "        )\n",
    "        ### Latent space transformations\n",
    "\n",
    "        self.mu = nn.Linear(256,latent_dim)\n",
    "        self.logvar = nn.Linear(256,latent_dim)\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(latent_dim, 256),\n",
    "\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256,latent_pixel_size*latent_pixel_size*channel_size*32),\n",
    "            nn.Unflatten(1,(32,channel_size,latent_pixel_size,latent_pixel_size)),\n",
    "\n",
    "            nn.ConvTranspose3d(32,32, kernel_size = 3, stride= 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose3d(32,16, kernel_size = (3,4,4), stride= (1,2,2), padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose3d(16,16, kernel_size = (3,3,3), stride= (1,1,1), padding = (1,1,1)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose3d(16, 8, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            \n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose3d(8, 1, kernel_size=(5,6,6), stride=(1,2,2), padding=2),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        \n",
    "        return mu, logvar\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)  # Calculate standard deviation from log variance\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "        \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim = 64, channel_size = 9):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, kernel_size=(3,4,4), stride=(1,2,2), padding=1),  # Example for 3D conv layer\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv3d(8, 4, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv3d(4,1, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*32*channel_size,64),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "        )\n",
    "        ### Latent space transformations\n",
    "\n",
    "        self.mu = nn.Linear(64,latent_dim)\n",
    "        self.logvar = nn.Linear(64,latent_dim)\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,32*32*channel_size),\n",
    "            nn.Unflatten(1,(1,channel_size,32,32)),\n",
    "\n",
    "            nn.ConvTranspose3d(1,4, kernel_size = (3,4,4), stride= (1,2,2), padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose3d(4, 8, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose3d(8, 1, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        \n",
    "        return mu, logvar\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)  # Calculate standard deviation from log variance\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "        \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim = 64, channel_size = 9,latent_pixel_size = 16):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            \n",
    "            nn.Conv3d(1, 8, kernel_size=(5,6,6), stride=(1,2,2), padding=(2,2,2)),  # Example for 3D conv layer\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv3d(8, 4, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.Conv3d(4,4, kernel_size = (3,3,3), stride= (1,1,1), padding = (1,1,1)),\n",
    "            nn.LeakyReLU(),\n",
    "            # nn.BatchNorm3d(4),\n",
    "            nn.Conv3d(4,1, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "        \n",
    "        \n",
    "            nn.LeakyReLU(),\n",
    "    \n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(latent_pixel_size*latent_pixel_size*channel_size,256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "        )\n",
    "        ### Latent space transformations\n",
    "\n",
    "        self.mu = nn.Linear(256,latent_dim)\n",
    "        self.logvar = nn.Linear(256,latent_dim)\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(latent_dim, 256),\n",
    "\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256,latent_pixel_size*latent_pixel_size*channel_size),\n",
    "            nn.Unflatten(1,(1,channel_size,latent_pixel_size,latent_pixel_size)),\n",
    "\n",
    "            nn.ConvTranspose3d(1,4, kernel_size = (3,4,4), stride= (1,2,2), padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose3d(4,4, kernel_size = (3,3,3), stride= (1,1,1), padding = (1,1,1)),\n",
    "            # nn.BatchNorm3d(4),\n",
    "            nn.ConvTranspose3d(4, 8, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose3d(8, 1, kernel_size=(5,6,6), stride=(1,2,2), padding=2),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        \n",
    "        return mu, logvar\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)  # Calculate standard deviation from log variance\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "        \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim = 64, channel_size = 9,latent_pixel_size = 16):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            \n",
    "            nn.Conv3d(1, 8, kernel_size=(5,6,6), stride=(1,2,2), padding=(2,2,2)),  # Example for 3D conv layer\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv3d(8,16, kernel_size = (3,3,3), stride= (1,1,1), padding = (1,1,1)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv3d(16, 16, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            nn.Conv3d(16,16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "      \n",
    "    \n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*latent_pixel_size*latent_pixel_size*channel_size,256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "        )\n",
    "        ### Latent space transformations\n",
    "\n",
    "        self.mu = nn.Linear(256,latent_dim)\n",
    "        self.logvar = nn.Linear(256,latent_dim)\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(latent_dim, 256),\n",
    "\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256,latent_pixel_size*latent_pixel_size*channel_size*16),\n",
    "            nn.Unflatten(1,(16,channel_size,latent_pixel_size,latent_pixel_size)),\n",
    "\n",
    "            nn.ConvTranspose3d(16 ,16, kernel_size = 3, stride= 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            \n",
    "            nn.ConvTranspose3d(16, 16, kernel_size=(3,4,4), stride=(1,2,2), padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose3d(16,8, kernel_size = (3,3,3), stride= (1,1,1), padding = (1,1,1)),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            \n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose3d(8, 1, kernel_size=(5,6,6), stride=(1,2,2), padding=2),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        \n",
    "        return mu, logvar\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)  # Calculate standard deviation from log variance\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "        \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim = 16,latent_pixel_size = 16):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=2, padding=2),  # Example for 3D conv layer\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(16,32, kernel_size = 5, stride= 1, padding = 2),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.Conv2d(32, 32, kernel_size=4, stride= 2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(32,32, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "      \n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*latent_pixel_size*latent_pixel_size,256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            \n",
    "        )\n",
    "        ### Latent space transformations\n",
    "\n",
    "        self.mu = nn.Linear(256,latent_dim)\n",
    "        self.logvar = nn.Linear(256,latent_dim)\n",
    "        \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(latent_dim, 256),\n",
    "\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256,32*latent_pixel_size*latent_pixel_size),\n",
    "            nn.Unflatten(1,(32,latent_pixel_size,latent_pixel_size)),\n",
    "\n",
    " \n",
    "            \n",
    "            nn.ConvTranspose2d(32,32, kernel_size = 3, stride =1, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride= 2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(16,8, kernel_size =  5, stride= 1, padding = 2),\n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            \n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=5, stride=2, padding=2, output_padding = 1),\n",
    "\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        \n",
    "        return mu, logvar\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)  # Calculate standard deviation from log variance\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "        \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar\n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
